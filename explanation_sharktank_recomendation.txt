{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ecfb84-6bd6-4d79-a201-8a25244b9a01",
   "metadata": {},
   "source": [
    "Explanation of the codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64480889-a846-4056-a2f2-6e3b7853e450",
   "metadata": {},
   "source": [
    "1. Importing Required Libraries\n",
    "python\n",
    "Copy code\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pandas: Used for data manipulation and analysis.\n",
    "TfidfVectorizer: Converts text data into numerical vectors based on term frequency and inverse document frequency (TF-IDF).\n",
    "MinMaxScaler: Scales numerical data to a range between 0 and 1.\n",
    "cosine_similarity: Measures the similarity between two vectors using cosine.\n",
    "TruncatedSVD: A dimensionality reduction technique to simplify the feature matrix while maintaining important data structure.\n",
    "matplotlib and seaborn: Used for creating plots and visualizations.\n",
    "\n",
    "2. Loading the Dataset\n",
    "python\n",
    "Copy code\n",
    "\n",
    "data = pd.read_csv('sharktank.csv')\n",
    "\n",
    "The pd.read_csv() function loads the dataset from a CSV file named sharktank.csv into a DataFrame called data.\n",
    "\n",
    "3. Selecting Relevant Columns\n",
    "python\n",
    "Copy code\n",
    "\n",
    "\n",
    "columns = [\n",
    "    'Industry', 'Business Description', 'Yearly Revenue', 'Number of Sharks in Deal'\n",
    "]\n",
    "df = data[columns].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "\n",
    "We choose specific columns that we will use for building the recommendation system: Industry, Business Description, Yearly Revenue, and Number of Sharks in Deal.\n",
    "5. Handling Missing Values\n",
    "python\n",
    "Copy code\n",
    "\n",
    "df['Business Description'] = df['Business Description'].fillna('')  # For text data\n",
    "df['Yearly Revenue'] = df['Yearly Revenue'].fillna(0)  # For numerical data\n",
    "df['Number of Sharks in Deal'] = df['Number of Sharks in Deal'].fillna(0)  # For numerical data\n",
    "\n",
    "Missing values in the Business Description column are filled with an empty string ('').\n",
    "Missing values in the Yearly Revenue and Number of Sharks in Deal columns are filled with 0 to ensure numerical calculations do not fail.\n",
    " \n",
    " 6.Ensuring Correct Data Types\n",
    "python\n",
    "Copy code\n",
    "\n",
    "df['Yearly Revenue'] = pd.to_numeric(df['Yearly Revenue'], errors='coerce')\n",
    "df['Number of Sharks in Deal'] = pd.to_numeric(df['Number of Sharks in Deal'], errors='coerce')\n",
    "\n",
    "This converts Yearly Revenue and Number of Sharks in Deal columns to numeric types. Any non-numeric values are converted to NaN (missing \n",
    "values), which are handled during preprocessing.\n",
    "\n",
    "7. Text Data Vectorization Using TF-IDF\n",
    "python\n",
    "Copy code\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "business_description_vectors = vectorizer.fit_transform(df['Business Description']).toarray()\n",
    "\n",
    "TfidfVectorizer converts the Business Description text into numerical feature vectors.\n",
    "The stop_words='english' argument removes common English words that don't add much meaning.\n",
    "The .toarray() method converts the sparse matrix output into a dense array.\n",
    "\n",
    "8. Normalizing Numerical Data\n",
    "python\n",
    "Copy code\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical_columns = ['Yearly Revenue', 'Number of Sharks in Deal']\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "MinMaxScaler scales the numerical columns to a range between 0 and 1, making the data comparable with the TF-IDF vectors.\n",
    "\n",
    "9. Combining Text and Numerical Features\n",
    "python\n",
    "Copy code\n",
    "\n",
    "combined_features = pd.DataFrame(business_description_vectors)\n",
    "combined_features[numerical_columns] = df[numerical_columns].values\n",
    "\n",
    "The dense array of business description vectors is converted into a DataFrame.\n",
    "Numerical columns are added to this DataFrame to create a combined feature matrix.\n",
    "\n",
    "10. Ensuring Column Names Are Strings for SVD\n",
    "python\n",
    "Copy code\n",
    "combined_features.columns = combined_features.columns.astype(str)\n",
    "\n",
    "This step ensures all column names are strings, as TruncatedSVD expects string feature names.\n",
    "\n",
    "11. Applying Truncated SVD for Dimensionality Reduction\n",
    "python\n",
    "Copy code\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "svd_features = svd.fit_transform(combined_features)\n",
    "\n",
    "TruncatedSVD reduces the dimensionality of the feature matrix to 50 components (adjustable).\n",
    "This helps capture the most important features and simplifies the similarity calculations.\n",
    "\n",
    "12. Creating the Similarity Matrix\n",
    "python\n",
    "Copy code\n",
    "\n",
    "similarity_matrix = cosine_similarity(svd_features)\n",
    "\n",
    "cosine_similarity calculates the cosine of the angle between vectors, giving a measure of similarity between episodes.\n",
    "\n",
    "13. Recommendation Function\n",
    "python\n",
    "Copy code\n",
    "\n",
    "def recommend_episodes(episode_index, top_n=5):\n",
    "    similarities = list(enumerate(similarity_matrix[episode_index]))\n",
    "    sorted_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    recommendations = [i[0] for i in sorted_similarities[1:top_n+1]]  # Skip the first (self)\n",
    "    return data.iloc[recommendations]\n",
    "\n",
    "The function recommend_episodes takes an episode_index and returns the top_n most similar episodes.\n",
    "It sorts the similarity scores in descending order and excludes the first entry (the episode itself).\n",
    "\n",
    "14. Testing the Recommendation System\n",
    "python\n",
    "Copy code\n",
    "\n",
    "selected_episode_index = 222  # Replace with your desired episode index\n",
    "recommendations = recommend_episodes(selected_episode_index, top_n=15)\n",
    "print(recommendations[['Season Number', 'Episode Number', 'Startup Name', 'Industry']])\n",
    "\n",
    "This code selects an episode by index (222 in this case) and prints the top 15 recommended episodes with their Season Number, Episode Number, Startup Name, and Industry.\n",
    "\n",
    "15. Optional: Visualizing the Similarity Matrix\n",
    "python\n",
    "Copy code\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_matrix, cmap='viridis', square=True, cbar_kws={'label': 'Similarity Score'})\n",
    "plt.title('Episode Similarity Matrix')\n",
    "plt.show()\n",
    "\n",
    "This step uses seaborn to create a heatmap visualization of the similarity matrix.\n",
    "It provides an intuitive way to see which episodes are most similar to each other based on the calculated features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
